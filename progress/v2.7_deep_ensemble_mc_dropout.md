# v2.7 — Deep Ensemble & MC Dropout Baselines (P4)

**Date:** 2026-02-28
**Goal:** Implement and evaluate B3 (Deep Ensemble) and B4 (MC Dropout) baselines to show that action-variance-based uncertainty is inferior to our decomposed approach.

## Methods

### B3: Deep Ensemble (DeepEnsemblePolicy)
- M=5 copies of pretrained actor with Gaussian weight perturbations (std=0.02)
- First member kept as original (unperturbed)
- Uncertainty = mean action variance across ensemble members
- When uncertainty > threshold (0.1): conservative scaling (same beta=0.3)
- **Cannot decompose**: treats all uncertainty as one signal

### B4: MC Dropout (MCDropoutPolicy)
- Dropout layers (p=0.1) inserted after each ELU activation in actor MLP
- M=10 forward passes with `model.train()` to keep dropout active
- Uncertainty = mean action variance across forward passes
- When uncertainty > threshold (0.1): conservative scaling (same beta=0.3)
- **Cannot decompose**: treats all uncertainty as one signal

### Actor Architecture (RSL-RL)
```
nn.Sequential: Linear(36,256) -> ELU -> Linear(256,256) -> ELU -> Linear(256,256) -> ELU -> Linear(256,8)
```

## Results — Noise Robustness (HIGH noise, 100 episodes, Lift)

| Method | Success Rate | Avg Reward |
|---|---|---|
| Vanilla | 58.0% | 45.85 |
| **Deep Ensemble (B3)** | **45.0%** | **25.62** |
| **MC Dropout (B4)** | **53.0%** | **29.67** |
| Multi-Sample | 96.1% | 119.16 |
| Total Uncertainty | 93.0% | 102.74 |
| **Decomposed (Ours)** | **93.0%** | **117.11** |

**Deep Ensemble and MC Dropout are WORSE than vanilla!** Both apply conservative scaling ~100% of the time because action variance is always above threshold under noisy observations. This is exactly what we want to show: action variance conflates noise-induced variance with true state uncertainty.

### Intervention Rates
- Deep Ensemble: 97.3% conservative, 2.7% normal
- MC Dropout: 100.0% conservative, 0.0% normal
- Total Uncertainty: 100.0% intervene, 0.0% normal
- Decomposed: 90.3% filter, 9.7% filter+conservative, 0% conservative-only

## Results — OOD Perturbation (HIGH noise + OOD, 100 episodes, Lift)

| Scenario | Vanilla | DeepEns | MCDrop | Multi-S | Total-U | **Decomp** | D-MS | D-TU |
|---|---|---|---|---|---|---|---|---|
| Mass 2x | 52.0% | 40.0% | 51.0% | 98.0% | 87.0% | **95.3%** | -2.7% | **+8.3%** |
| Mass 5x | 35.0% | 19.0% | 32.0% | 82.2% | 62.0% | **76.0%** | -6.2% | **+14.0%** |
| Mass 10x | 2.0% | 2.0% | 2.0% | 18.4% | 14.0% | 15.0% | -3.4% | +1.0% |
| Friction 0.5x | 48.0% | 56.0% | 44.0% | 96.1% | 88.0% | **95.0%** | -1.1% | **+7.0%** |
| Friction 0.2x | 49.0% | 38.6% | 47.0% | 94.0% | 92.0% | 90.6% | -3.4% | -1.4% |
| Gravity 1.5x | 58.0% | 55.5% | 55.5% | 96.1% | 89.1% | **97.7%** | **+1.6%** | **+8.6%** |

## Key Insights

1. **Action variance is a poor uncertainty signal**: Both Deep Ensemble and MC Dropout apply conservative scaling nearly 100% of the time under noise — they cannot distinguish noise from OOD
2. **Conservative-only hurts under noise**: The robot needs full action magnitude to successfully manipulate objects; blanket scaling reduces performance below vanilla
3. **Multi-sample averaging is the dominant intervention**: Under noise, filtering observations is far more effective than scaling actions
4. **Decomposition value confirmed**: Our method correctly identifies noise as aleatoric (filter) and OOD as epistemic (conservative), applying the RIGHT intervention for each case
5. **Deep Ensemble even worse than MC Dropout**: Weight perturbation introduces additional variance that exacerbates the false-alarm problem

## Why Action Variance Fails

The fundamental issue: under observation noise, different noisy inputs produce different actions even for the same policy. This action-level variance is confused with model uncertainty by both Deep Ensemble and MC Dropout. Our decomposition operates in OBSERVATION space where we can cleanly separate:
- **Multi-Sample Variance**: Measures NOISE by comparing multiple noisy readings of the same state
- **Mahalanobis Distance**: Measures OOD-ness by comparing against calibration distribution

## Implementation

- Added `DeepEnsemblePolicy` and `MCDropoutPolicy` to `uncertainty/intervention.py`
- Integrated into `evaluate_decomposed.py` and `evaluate_ood.py`
- All 6 methods now evaluated: Vanilla, Deep Ensemble, MC Dropout, Multi-Sample, Total Uncertainty, Decomposed

## Parameters
```
Deep Ensemble: M=5, perturbation_std=0.02, threshold=0.1, beta=0.3
MC Dropout: dropout_p=0.1, M=10, threshold=0.1, beta=0.3
Same beta=0.3 for all methods with conservative scaling
100 episodes per method/scenario, seed=42, noise_level=high
```

## Result Files
- Noise evaluation: `results/decomposed_high_20260228_232330/`
- OOD evaluation: `results/ood_high_20260228_233038/`
